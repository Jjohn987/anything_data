<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width,minimum-scale=1,maximum-scale=1">

  
    
    
      <link href="/css/fonts.css" rel="stylesheet" type="text/css">
    
  

  
  <title>Part II: Chinese Classics&#39; Word/Network Plots</title>

  
  
  <link rel="stylesheet" href="/css/hugo-octopress.css">

  
  

  
    <link rel="stylesheet" href="/css/fork-awesome.min.css">
  

  
  <link href="/favicon.png" rel="icon">

  
  
  

  

  <meta name="description" content="My R blog, with projects in analytics, text analysis, data mining, and visualization. I might occasionally include Chinese text.">
  <meta name="keywords" content="">

  <meta name="author" content="Jeremy Johnson">

  
  <meta name="generator" content="Hugo 0.40.2" />

  
  
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-118999723-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


  
  

</head>
<body>


<header role="banner"><hgroup>
  
  <h1><a href="/">Anything is |Data| is Anything</a></h1>
    <h2>The investigation of things...</h2>
</hgroup></header>


<nav role="navigation">
<fieldset class="mobile-nav">
  
  <select onchange="location = this.value;">
    <option value="">Navigate…</option>
      

  </select>
</fieldset>


<ul class="main-navigation">
  
  
</ul>


<ul class="subscription">
  

</ul>


</nav>


<div id="main">
  <div id="content">
    <div>
      <article class="hentry" role="article">

        
        

<header>
    <p class="meta">Jun 8, 2018
         - 8 minute read 
         - <a href="/blog/2018-06-08-part-ii-chinese-classics-word/network-plots/#disqus_thread">Comments</a>

        
        
        
            - <a class="label" href="/categories/network-analysis/">Network Analysis </a><a class="label" href="/categories/text-analysis/">Text Analysis </a>
        
    </p>
    <h1 class="entry-title">
         Part II: Chinese Classics&#39; Word/Network Plots 
    </h1>
</header>


        <div class="entry-content">
          
          
          
          
          <p>This is a continuation in my series of exploratory text analysis of 3 Chinese classic works. In the previous post, I calculated word counts for each book, and visualized common words using bar charts. This time, I’d like to examine word use <strong>across</strong> the texts with network visualization. The goal is to help see <strong>what’s common</strong> and <strong>what’s different</strong> between the texts regarding word usage.</p>
<p>Network visualization is particularly helpful for discovering simularities and differences between objects - this is because nodes and edges can form connections and clusters (or stay isolated). Thus, through a network structure we can get an idea of commonalities and differences between the word usages in these 3 works.</p>
<p>Disclaimer - the setup of this post is very similar to last time. I’m essentially importing the same data. So just skip past these first 2 code blocks.</p>
<pre class="r"><code>library(tidyverse)
library(readr)
library(stringi)
library(tidygraph)
library(ggraph)


my_classics &lt;- read_csv(&quot;~/Desktop/anything_data/content/post/my_classics.csv&quot;) %&gt;%
  select(-1) %&gt;%
  mutate(book = str_to_title(book))</code></pre>
<pre class="r"><code>simple_bigram &lt;- function(x) {
  if(length(x) &lt; 2) {
    return(NA)
  } else {
    output_length &lt;- length(x) - 1
    output &lt;- vector(length = output_length)
    for(i in 1:output_length) {
      output[i] &lt;- paste(x[i], x[i+1], sep = &quot; &quot;)
    }
    output
  }
}

tokenizer &lt;- function(text) {
  unlist(lapply(stringi::stri_split_boundaries(text), function(x) simple_bigram(x)))
}

library(tmcn)

stopwordsCN &lt;- data.frame(word = c(tmcn::stopwordsCN(),
                                   &quot;子曰&quot;, &quot;曰&quot;, &quot;於&quot;, &quot;則&quot;,&quot;吾&quot;, &quot;子&quot;, &quot;不&quot;, &quot;無&quot;, &quot;斯&quot;,&quot;與&quot;, &quot;為&quot;, &quot;必&quot;,
                                   &quot;使&quot;, &quot;非&quot;,&quot;天下&quot;, &quot;以為&quot;,&quot;上&quot;, &quot;下&quot;, &quot;人&quot;, &quot;天&quot;, &quot;不可&quot;, &quot;謂&quot;, &quot;是以&quot;,
                                   &quot;而不&quot;, &quot;皆&quot;, &quot;不亦&quot;, &quot;乎&quot;, &quot;之&quot;, &quot;而&quot;, &quot;者&quot;, &quot;本&quot;, &quot;與&quot;, &quot;吾&quot;, &quot;則&quot;,
                                   &quot;以&quot;, &quot;其&quot;, &quot;為&quot;, &quot;不以&quot;, &quot;不可&quot;, &quot;也&quot;, &quot;矣&quot;, &quot;子&quot;, &quot;由&quot;, &quot;子曰&quot;, &quot;曰&quot;,
                                   &quot;非其&quot;, &quot;於&quot;, &quot;不能&quot;, &quot;如&quot;, &quot;斯&quot;, &quot;然&quot;, &quot;君&quot;, &quot;亦&quot;, &quot;言&quot;, &quot;聞&quot;, &quot;今&quot;,
                                   &quot;君&quot;, &quot;不知&quot;, &quot;无&quot;))

##High frequency single-words by chapter
chapter_words &lt;- my_classics %&gt;%
  mutate(word = map(word, function(x) unlist(stringi::stri_split_boundaries(x)))) %&gt;%
  unnest(word) %&gt;%
  mutate(word = str_replace_all(word, &quot;[「」《》『』,，、。；：？！]&quot;, &quot;&quot;)) %&gt;%
  filter(!is.na(word), !grepl(&quot;Invald&quot;, word)) %&gt;%
  anti_join(stopwordsCN) %&gt;%
  select(word, book, chapter_number) %&gt;% 
  count(book, chapter_number, word) %&gt;%
  group_by(book, chapter_number) %&gt;%
  mutate(frequency = n/sum(n), book_edges = book) %&gt;%
  filter(frequency &gt; .01) %&gt;% ungroup() %&gt;%
  select(word, book, n, frequency, book_edges)

book_words &lt;- my_classics %&gt;%
  mutate(word = map(word, function(x) unlist(stringi::stri_split_boundaries(x)))) %&gt;%
  unnest(word) %&gt;%
  mutate(word = str_replace_all(word, &quot;[「」《》『』,，、。；：？！]&quot;, &quot;&quot;)) %&gt;%
  filter(!is.na(word), !grepl(&quot;Invald&quot;, word)) %&gt;%
  anti_join(stopwordsCN) %&gt;%
  select(word, book) %&gt;% 
  count(book, word) %&gt;%
  group_by(book) %&gt;%
  mutate(frequency = n/sum(n), book_edges = book) %&gt;%
  filter(frequency &gt; .001) </code></pre>
<p>Plotting the edges in “arcs” helps avoid any overplotting or tangling that might exist in the case of too much interconnectivity, as we will soon see.</p>
<p>I’ve got 2 different ways of visualizing networks using words in these texts. First, let’s look at single word use between each text, one plot showing common words by each chapter/book, another by book.</p>
<p>Unfortunatly the blog squishes the plot a bit, so you might want to zoom in on it.</p>
<div id="single-words-by-chapter-and-book" class="section level2">
<h2>Single Words by Chapter and Book</h2>
<pre class="r"><code>knitr::opts_chunk$set(fig.width=16, fig.height=12)

as_tbl_graph(chapter_words, directed = FALSE) %&gt;% ggraph(layout = &quot;fr&quot;) + 
  geom_edge_arc(aes(edge_width = frequency, color = factor(book_edges), alpha = frequency)) +
  geom_node_point(color = &quot;black&quot;, alpha = .65, size = 7, show.legend = FALSE) + 
  geom_node_text(aes(label = name), color = &quot;white&quot;,
                 family = &quot;HiraKakuProN-W3&quot;, check_overlap = TRUE) +
  scale_edge_colour_manual(values = c(&quot;#b20047&quot;, &quot;#00b274&quot;, &quot;#FFB52A&quot;)) + 
  theme(axis.text.x = element_blank()) + 
  theme(axis.text.y = element_blank()) + 
  theme(panel.background = element_rect(fill = &quot;#cddbda&quot;),
        plot.background = element_rect(fill = &quot;#cddbda&quot;),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.margin = margin(0, 0, 0, 0, &quot;cm&quot;)) + 
  guides(edge_width=FALSE, edge_alpha = FALSE) + 
  labs(x = NULL, y = NULL,
       title = &quot;\nCommon Characters\n in the Analects, Mozi, and Zhuangzi\n&quot;) +
  theme(plot.title = element_text(size = 25, vjust = -10, hjust = 0.5,
                                  family = &quot;Palatino&quot;, face = &quot;bold.italic&quot;,
                                  color = &quot;#3d4040&quot;)) + 
  theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(),
        legend.key = element_rect(color = &quot;#454444&quot;, fill = &quot;#f5fffe&quot;),
        legend.text = element_text(size = 12, color = &quot;#3d4040&quot;, family = &quot;Palatino&quot;),
        legend.key.width = unit(4, &quot;line&quot;),
        legend.background = element_rect(fill = &quot;#cddbda&quot;))</code></pre>
<p><img src="/post/2018-06-08-part-ii-chinese-classics-word-network-plots_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Compared to the above, doing the frequency counting by book seems to yeild a bit more balanced results. Of course frequency values become much lower that way, here I filter for greater than .001.</p>
</div>
<div id="single-words-by-book" class="section level2">
<h2>Single Words by Book</h2>
<pre class="r"><code>as_tbl_graph(book_words, directed = FALSE) %&gt;%
  ggraph(layout = &quot;fr&quot;) + 
  geom_edge_arc(aes(edge_width = frequency, color = factor(book_edges), alpha = frequency)) +
  geom_node_point(color = &quot;black&quot;, alpha = .65, size = 7, show.legend = FALSE) + 
  geom_node_text(aes(label = name), color = &quot;white&quot;,
                 family = &quot;HiraKakuProN-W3&quot;, check_overlap = TRUE) +
  scale_edge_colour_manual(values = c(&quot;#b20047&quot;, &quot;#00b274&quot;, &quot;#FFB52A&quot;)) + 
  theme(axis.text.x = element_blank()) + 
  theme(axis.text.y = element_blank()) + 
  theme(panel.background = element_rect(fill = &quot;#cddbda&quot;),
        plot.background = element_rect(fill = &quot;#cddbda&quot;),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.margin = margin(0, 0, 0, 0, &quot;cm&quot;)) + 
  guides(edge_width=FALSE, edge_alpha = FALSE) + 
  labs(x = NULL, y = NULL,
       title = &quot;\nCommon Characters\n in the Analects, Mozi, and Zhuangzi\n&quot;, caption = &quot;Per Book, Frequency &gt; .001&quot;) +
  theme(plot.title = element_text(size = 25, vjust = -10, hjust = 0.5,
                                  family = &quot;Palatino&quot;, face = &quot;bold.italic&quot;,
                                  color = &quot;#3d4040&quot;)) + 
  theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(),
        legend.key = element_rect(color = &quot;#454444&quot;, fill = &quot;#f5fffe&quot;),
        legend.text = element_text(size = 12, color = &quot;#3d4040&quot;, family = &quot;Palatino&quot;),
        legend.key.width = unit(4, &quot;line&quot;),
        legend.background = element_rect(fill = &quot;#cddbda&quot;))</code></pre>
<p><img src="/post/2018-06-08-part-ii-chinese-classics-word-network-plots_files/figure-html/unnamed-chunk-4-1.png" width="1536" /></p>
<p>Regardless of calculating frequency by chapter and book or just by book, there are plenty of words that fall <strong>in between</strong> texts.</p>
<p>I’m not sure how useful this method of examining “simularity” of word usage is analytically; however, I think it works in a sense. If not for an algorithm, then at least for our general understanding. However, I do suspect that this type of networking does play into clustering, and from the looks of the plots, I imagine that the LDA algorithm might run into confusion distinguishing the books/chapters later.</p>
</div>
<div id="now-lets-plot-bigrams" class="section level2">
<h2>Now let’s plot bigrams</h2>
<p>Here, a bigram is essentially two connected nodes. The connections (edges) between them are colored according to the text they appear in. Again, its a bit subjective on whether to calculate the bigrams by book or by each chapter and book. Conventional wisdom tells me that doing the calculation per chapter makes more sense, however, the Zhuangzi suffers from this operation. (Perhaps it has a greater word diversity per chapter?) So I decide to plot both ways.</p>
</div>
<div id="bigrams-by-chapter-and-book" class="section level2">
<h2>Bigrams by Chapter and Book</h2>
<pre class="r"><code>knitr::opts_chunk$set(fig.width=6, fig.height=6, fig.pos = &quot;center&quot;)

bigrams &lt;- my_classics %&gt;%
  mutate(word = str_replace_all(word, &quot;[「」《》『』,，、。；：？！]&quot;, &quot;&quot;)) %&gt;%
  mutate(word = map(word, function(x) tokenizer(x))) %&gt;%
  unnest(word) %&gt;%
  filter(!is.na(word)) %&gt;%
  separate(word, into = c(&quot;word1&quot;, &quot;word2&quot;)) %&gt;%
  filter(!word1 %in% stopwordsCN$word, !word2 %in% stopwordsCN$word) %&gt;%
  unite(&quot;word&quot;, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;)

chapter_bigrams &lt;- bigrams %&gt;%
  count(book, chapter_number, word) %&gt;%
  arrange(book, -n) %&gt;%
  group_by(book, chapter_number) %&gt;%
  mutate(frequency = n/sum(n)) %&gt;%
  ungroup() %&gt;%
  select(-chapter_number)


chapter_bigrams %&gt;%
  separate(word, into = c(&quot;word1&quot;, &quot;word2&quot;)) %&gt;%
  select(word1, word2, n, frequency, book) %&gt;%
  filter(frequency &gt;= .02) %&gt;%
  as_tbl_graph(directed = FALSE) %&gt;%
  ggraph(layout = &quot;fr&quot;) + 
  geom_edge_density() +
  geom_edge_arc(aes(color = book),
                alpha = .70, arrow = arrow(length = unit(1.5, &quot;mm&quot;)),
                start_cap = circle(3, &quot;mm&quot;), end_cap = circle(3, &quot;mm&quot;), edge_width = .75) +
  geom_node_point(size = 7, color = &quot;black&quot;, alpha = .75) +
  geom_node_text(aes(label = name), color = &quot;grey&quot;, family = &quot;HiraKakuProN-W3&quot;, check_overlap = TRUE) +
  scale_edge_colour_manual(values = c(&quot;#b20047&quot;, &quot;#00b274&quot;, &quot;#fdff00&quot;))+
  theme(axis.text.x = element_blank()) +
  theme(axis.text.y = element_blank()) +
  theme(panel.background = element_rect(fill = &quot;#8AE3C2&quot;),
        plot.background = element_rect(fill = &quot;#8AE3C2&quot;),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.margin = margin(0, 0, 0, 0, &quot;cm&quot;)) + 
  guides(edge_width=FALSE) +
  labs(x = NULL, y = NULL, title = &quot;Bigrams in the Analects, Mozi, and Zhuangzi&quot;, caption = &quot;Per chapter, Frequency &gt; .02&quot;) +
  theme(plot.title = element_text(size = 35, vjust = -10, hjust = 0.5,
                                  family = &quot;Palatino&quot;, face = &quot;italic&quot;,
                                  color = &quot;black&quot;)) +
  theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(),
        legend.key = element_rect(color = &quot;black&quot;, fill = &quot;#8AE3C2&quot;),
        legend.text = element_text(size = 12, color = &quot;black&quot;, family = &quot;Palatino&quot;),
        legend.key.width = unit(4, &quot;line&quot;),
        legend.background = element_rect(fill = &quot;#8AE3C2&quot;))</code></pre>
<p><img src="/post/2018-06-08-part-ii-chinese-classics-word-network-plots_files/figure-html/unnamed-chunk-5-1.png" width="1536" /> For the final plot, unfortunately many edges/links don’t show. Perhaps it is because many nodes are positioned so close together that the edges just aren’t drawn.</p>
</div>
<div id="bigrams-by-book" class="section level2">
<h2>Bigrams by Book</h2>
<pre class="r"><code>knitr::opts_chunk$set(fig.width=6, fig.height=6, fig.pos = &quot;center&quot;)

book_bigrams &lt;- bigrams %&gt;%
  count(book, word) %&gt;%
  arrange(book, -n) %&gt;%
  group_by(book) %&gt;%
  mutate(frequency = n/sum(n)) %&gt;%
  ungroup()

book_bigrams %&gt;%
  separate(word, into = c(&quot;word1&quot;, &quot;word2&quot;)) %&gt;%
  select(word1, word2, n, frequency, book) %&gt;%
  filter(frequency &gt;= .001) %&gt;%
  as_tbl_graph(directed = FALSE) %&gt;%
  ggraph(layout = &quot;fr&quot;) + 
  geom_edge_density() +
  geom_edge_arc(aes(color = book),
                alpha = .70, arrow = arrow(length = unit(1.5, &quot;mm&quot;)),
                start_cap = circle(3, &quot;mm&quot;), end_cap = circle(3, &quot;mm&quot;), edge_width = .75) +
  geom_node_point(size = 7, color = &quot;black&quot;, alpha = .75) +
  geom_node_text(aes(label = name), color = &quot;grey&quot;, family = &quot;HiraKakuProN-W3&quot;, check_overlap = TRUE) +
  scale_edge_colour_manual(values = c(&quot;#b20047&quot;, &quot;#00b274&quot;, &quot;#fdff00&quot;))+
  theme(axis.text.x = element_blank()) +
  theme(axis.text.y = element_blank()) +
  theme(panel.background = element_rect(fill = &quot;#8AE3C2&quot;),
        plot.background = element_rect(fill = &quot;#8AE3C2&quot;),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.margin = margin(0, 0, 0, 0, &quot;cm&quot;)) + 
  guides(edge_width=FALSE) +
  labs(x = NULL, y = NULL, title = &quot;Bigrams in\n the Analects, Mozi, and Zhuangzi&quot;, caption = &quot;Per book, Frequency &gt; .001&quot;) +
  theme(plot.title = element_text(size = 25, vjust = -10, hjust = 0.5,
                                  family = &quot;Palatino&quot;, face = &quot;italic&quot;,
                                  color = &quot;black&quot;)) +
  theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(),
        legend.key = element_rect(color = &quot;black&quot;, fill = &quot;#8AE3C2&quot;),
        legend.text = element_text(size = 12, color = &quot;black&quot;, family = &quot;Palatino&quot;),
        legend.key.width = unit(4, &quot;line&quot;),
        legend.background = element_rect(fill = &quot;#8AE3C2&quot;))</code></pre>
<p><img src="/post/2018-06-08-part-ii-chinese-classics-word-network-plots_files/figure-html/unnamed-chunk-6-1.png" width="576" /></p>
<p>There we have it, two different network plots of words used in these 3 classic works. In the case of the single characters, there is a lot of commonality (as expected). In the case of the bigrams, there is a lot less in common between the works.</p>
<p>Before I close, I’d like to comment briefly on the <code>tidygraph</code> package which made these plots possible. Previously, I used igraph and found it powerful and quite robust, yet not too intuitive or user-friendly. Tidygraph changes all of that and allows network data to be manipulated in a way similar to the tidyverse methodology. I love tidygraph!</p>
<p>I hope you enjoyed these two network plots. Until next time!</p>
</div>

        </div>
        

<footer>
  <p class="meta">
    <span class="byline author vcard">Posted by <span class="fn">Jeremy Johnson</span></span>
    
    <time>Jun 8, 2018</time>
    
      <span class="categories">
        Tags:
        
          <a class="category" href="/tags/tidygraph">tidygraph</a>  <a class="category" href="/tags/ggraph">ggraph</a>  <a class="category" href="/tags/chinese-text-analysis">Chinese text analysis</a>  
    
    </span>
  </p>

  
  

  

  <p class="meta">
    
        <a class="basic-alignment left" href="/blog/2018-06-01-plotting-word-bigrams-with-3-chinese-classics/" title="Plotting Word Bigrams with 3 Chinese Classics">Plotting Word Bigrams with 3 Chinese Classics</a>
    

    
      <a class="basic-alignment right" href="/blog/2018-09-21-first-app---halo-5-stats/" title="First App - Halo 5 Stats">First App - Halo 5 Stats</a>
    
  </p>
  
    
      <div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'anything-is-data-is-anything';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    
  
</footer>

      </article>
    </div>
    

<aside class="sidebar thirds">
  <section class="first odd">

    
      <h1>About Me</h1>
    

    <p>
      
        <p>I&rsquo;m Jeremy, and am deeply interested in data science. Especially R.
  <br><br>
  But my educational background is in <strong>Chinese</strong> and German. <strong>Think that&rsquo;s unrelated with R</strong>? <br>
  <br> Well, I see language is a door to another world, and data science as a skillset to understanding it. <br><br> <strong>Anything is Data, and Data is Anything</strong>.
  </br><br>
  <em>Cool Websites</em> <br>
  <a href="https://www.r-bloggers.com">https://www.r-bloggers.com</a> <br></p>

<p><strong>Me on Other Platforms:</strong>  </br></p>

      
    </p>
  </section>



  
  <ul class="sidebar-nav">
    <li class="sidebar-nav-item">
      <a target="_blank" href="https://github.com/Jjohn987/" title="https://github.com/Jjohn987/"><i class="fa fa-github fa-3x"></i></a>
      
      
      
      
         
      
      <a target="_blank" href="https://www.linkedin.com/in/jeremy-johnson-09016a112" title="https://www.linkedin.com/in/jeremy-johnson-09016a112"><i class="fa fa-linkedin fa-3x"></i></a>
      <a target="_blank" href="https://stackexchange.com/users/11094434/superball10000" title="https://stackexchange.com/users/11094434/superball10000"><i class="fa fa-stack-overflow fa-3x"></i></a>
      
      
      
      
      

    
    
    </li>
  </ul>

  

  

  
  
  
    
      <section class="even">
        <h1>Recent Posts</h1>
        <ul id="recent_posts">
          
          
            
              <li class="post">
                <a href="/blog/2018-09-21-first-app---halo-5-stats/">First App - Halo 5 Stats</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-06-08-part-ii-chinese-classics-word/network-plots/">Part II: Chinese Classics&#39; Word/Network Plots</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-06-01-plotting-word-bigrams-with-3-chinese-classics/">Plotting Word Bigrams with 3 Chinese Classics</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-05-29-a-tidytext-analysis-of-3-chinese-classics/">A Tidytext Analysis of 3 Chinese Classics</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-05-17-ctextclassics-my-first-package/">Ctextclassics, my First Package</a>
              </li>
            
          
        </ul>
      </section>
    
  
</aside>

  </div>
</div>

<footer role="contentinfo">
  <p>Copyright &copy; 2018 Jeremy Johnson - <a href="/license/">License</a> -
  <span class="credit">Powered by <a target="_blank" href="https://gohugo.io">Hugo</a> and <a target="_blank" href="https://github.com/parsiya/hugo-octopress/">Hugo-Octopress</a> theme.
</p>

</footer>






</body>
</html>

