<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width,minimum-scale=1,maximum-scale=1">

  
    
    
      <link href="/css/fonts.css" rel="stylesheet" type="text/css">
    
  

  
  <title>Top MBA Programs by US News</title>

  
  
  <link rel="stylesheet" href="/css/hugo-octopress.css">

  
  

  
    <link rel="stylesheet" href="/css/fork-awesome.min.css">
  

  
  <link href="/favicon.png" rel="icon">

  
  
  

  

  <meta name="description" content="My R blog, with projects in analytics, text analysis, data mining, and visualization. I might occasionally include Chinese text.">
  <meta name="keywords" content="">

  <meta name="author" content="Jeremy Johnson">

  
  <meta name="generator" content="Hugo 0.40.2" />

  
  
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-118999723-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


  
  

</head>
<body>


<header role="banner"><hgroup>
  
  <h1><a href="/">Anything is |Data| is Anything</a></h1>
    <h2>The investigation of things...</h2>
</hgroup></header>


<nav role="navigation">
<fieldset class="mobile-nav">
  
  <select onchange="location = this.value;">
    <option value="">Navigate…</option>
      

  </select>
</fieldset>


<ul class="main-navigation">
  
  
</ul>


<ul class="subscription">
  

</ul>


</nav>


<div id="main">
  <div id="content">
    <div>
      <article class="hentry" role="article">

        
        

<header>
    <p class="meta">Jul 1, 2017
         - 4 minute read 
         - <a href="/blog/2017-07-01-top-mba-programs-by-us-news/#disqus_thread">Comments</a>

        
        
        
            - <a class="label" href="/categories/scraping/">scraping </a>
        
    </p>
    <h1 class="entry-title">
         Top MBA Programs by US News 
    </h1>
</header>


        <div class="entry-content">
          
          
          
          
          <p>Somebody once asked me for reccomendations on MBA programs based on rank and tuition. I didn’t have any information on hand, but knew how toget it. Webscraping.</p>
<p>Webscraping is an immensly useful tool for gathering data from webpages, when it isn’t hosted on an API or stored in a file somewhere. R’s best tool for webscraping is <strong>Rvest.</strong></p>
<p>So I decided to scrape information on the US News website for university rankings, which has at least 20 pages of MBA probrams available. To copy and paste that much data into a spreadsheet would be annoying and quite an eye strain.</p>
<pre class="r"><code>library(tidyverse)
library(stringr)
library(rvest)</code></pre>
<p>Of course, before writing a scraper, one needs to code it according to the page layout.</p>
<p>I find that:</p>
<ul>
<li>There are 19 pages of information I need.</li>
<li>Everything is directly available on those pages, no need to iterate over additional, internal links.</li>
<li>Xpath selectors perform better than CSS selectors in this particular example.</li>
</ul>
<p>I will use lapply to run through all 19 pages, with the sprintf function to help paste the new page number in each time, for each new iteration.</p>
<pre class="r"><code>## 19 pages of MBA programs on US News website.
pages &lt;- 1:19

get_usnews_mbas &lt;- function(x) {
  website1 &lt;- &#39;https://www.usnews.com/best-graduate-schools/top-business-schools/mba-rankings/page+%s&#39;
  url &lt;- sprintf(website1, x, collapse = &quot;&quot;)
  website &lt;- read_html(url)
  base_url &lt;- &#39;http://www.usnews.com&#39;
  
  University &lt;- website %&gt;%
    html_nodes(&#39;.school-name&#39;) %&gt;%
    html_text()
 
   Location &lt;- website %&gt;%
    html_nodes(xpath = &#39;//*[@id=&quot;article&quot;]/table/tbody/tr/td[2]/p&#39;) %&gt;%
    html_text()
 
    Link &lt;- website %&gt;%
    html_nodes(xpath = &#39;//*[@id=&quot;article&quot;]/table/tbody/tr/td[2]/a&#39;) %&gt;%
    html_attr(&quot;href&quot;) %&gt;%
    str_trim(side = &quot;both&quot;)
 
     Tuition &lt;- website %&gt;%
    html_nodes(xpath = &#39;//*[@id=&quot;article&quot;]/table/tbody/tr/td[3]&#39;) %&gt;%
    str_replace_all(&quot;\n&quot;, &quot;&quot;) %&gt;%
    str_replace_all(&quot;,&quot;, &quot;&quot;) %&gt;%
    str_extract(&quot;\\d+&quot;) %&gt;%
    as.integer()
  
  ##Combine vectors into data frame
  data_frame(University,
             Location,
             Tuition,
             Link)
}</code></pre>
<div id="apply-the-function-get-the-data" class="section level2">
<h2>Apply the function, get the data!</h2>
<pre class="r"><code>USNEWS_MBAS &lt;- do.call(rbind, lapply(pages, get_usnews_mbas))</code></pre>
<p>Rvest made this feel almost like magic - Pulling it into R without having to do any manual clicking, copying, and pasting. As I said, web scraping is very powerful!</p>
</div>
<div id="clean-the-data" class="section level2">
<h2>Clean the Data</h2>
<pre class="r"><code>##Split location into City and State.

USNEWS_MBAS &lt;- USNEWS_MBAS %&gt;%
  separate(Location, c(&quot;City&quot;, &quot;State&quot;), sep = &quot;,&quot;)

##Create column for rankings... 

USNEWS_MBAS &lt;- USNEWS_MBAS %&gt;%
  mutate(Rank = 1: n())

##The URL&#39;s didnt scrape 100% correctly. But it is easy to paste the base URL onto each branch.
base_url &lt;- &#39;www.usnews.com&#39;

USNEWS_MBAS &lt;- USNEWS_MBAS %&gt;%
  mutate(base_url = base_url) %&gt;%
  unite(Links, base_url, Link, sep = &quot;&quot;)</code></pre>
<p>That’s enough data cleaning, but adding a variable to segment or classify the schools into brackets of ten could be useful when visualizing them in terms of rank and tuition cost later.</p>
<pre class="r"><code>USNEWS_MBAS &lt;- USNEWS_MBAS %&gt;%
  mutate(Tier = cut(Rank, breaks = seq(0, 400, by = 10))) %&gt;%
  mutate(Tier = str_replace(Tier, &quot;,&quot;, &quot;-&quot;)) %&gt;% 
  mutate(Tier = str_replace_all(Tier, &quot;[^0-9-]&quot;, &quot;&quot;))

##Convert intervals into factors  

USNEWS_MBAS$Tier &lt;- factor(USNEWS_MBAS$Tier, levels = c(&quot;0-10&quot;, &quot;10-20&quot;, &quot;20-30&quot;, &quot;30-40&quot;, &quot;40-50&quot;, &quot;50-60&quot;, &quot;60-70&quot;, &quot;70-80&quot;, &quot;80-90&quot;, &quot;90-100&quot;, &quot;Out of Top 100&quot;))

USNEWS_MBAS %&gt;%
  select(University, City, State, Tuition, Rank, Tier, Links)</code></pre>
<pre><code>## # A tibble: 475 x 7
##    University        City   State Tuition  Rank Tier  Links               
##    &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;chr&gt;               
##  1 Harvard Universi… Boston &quot; MA&quot;   72000     1 0-10  www.usnews.com/best…
##  2 University of Ch… Chica… &quot; IL&quot;   69200     2 0-10  www.usnews.com/best…
##  3 University of Pe… Phila… &quot; PA&quot;   70200     3 0-10  www.usnews.com/best…
##  4 Stanford Univers… Stanf… &quot; CA&quot;   68868     4 0-10  www.usnews.com/best…
##  5 Massachusetts In… Cambr… &quot; MA&quot;   71000     5 0-10  www.usnews.com/best…
##  6 Northwestern Uni… Evans… &quot; IL&quot;   68955     6 0-10  www.usnews.com/best…
##  7 University of Ca… Berke… &quot; CA&quot;   58794     7 0-10  www.usnews.com/best…
##  8 University of Mi… Ann A… &quot; MI&quot;   62300     8 0-10  www.usnews.com/best…
##  9 Columbia Univers… New Y… &quot; NY&quot;   71544     9 0-10  www.usnews.com/best…
## 10 Dartmouth Colleg… Hanov… &quot; NH&quot;   68910    10 0-10  www.usnews.com/best…
## # ... with 465 more rows</code></pre>
<p>Let’s filter the schools and grab only the top 100.</p>
<pre class="r"><code>USNEWS_MBAS %&gt;%
  filter(Rank &lt;= 100) %&gt;%
  ggplot(aes(x = Rank, y = Tuition, color = Tier)) + geom_point() +
  ggtitle(&quot;American MBA Programs&quot;, subtitle = &quot;By Rank and Tuition&quot;)</code></pre>
<p><img src="/post/2018-05-06-top-mba-programs-by-us-news_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Some top 20-30 schools look to be a good deal in terms of high rank and (relatively) lower tuition. But if one goes for schools ranked in the 30-40 range, then the tuition gets even lower.</p>
</div>
<div id="a-more-detailed-look" class="section level2">
<h2>A more detailed look</h2>
<pre class="r"><code>USNEWS_MBAS %&gt;%
  select(University, Rank, Tuition, Tier) %&gt;%
  arrange(Rank, Tuition) %&gt;%
  group_by(Tier) %&gt;%
  top_n(-3, Tuition) %&gt;%
  ggplot(aes(x = reorder(University, -Rank), y = Tuition, fill = Tier)) +
  geom_bar(stat = &quot;identity&quot;) + 
coord_flip() +
  ggtitle(&quot;Three &#39;Cheapest&#39; Schools per Tier&quot;, subtitle = &quot;MBA Programs&quot;) +
  xlab(&quot;University&quot;)</code></pre>
<p><img src="/post/2018-05-06-top-mba-programs-by-us-news_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Up above, I selected 3 institutions from each “Tier” of rankings with the lowest tuition and plotted them. Some universities have suspiciously low tuition, which is likely due to documentation error on the US News website.</p>
</div>
<div id="some-observations" class="section level2">
<h2>Some Observations</h2>
<ul>
<li>MBA programs are very expensive for any institution ranked from 1-30.</li>
<li>Programs become affordable from ranks 30-50 and onward</li>
<li>Anything that appears especially low is probably an inconsistency in US News’ tuition data.</li>
<li>It’d be better to compare school rankings across a certain program instead of comprehensively</li>
</ul>
<p><em>Migrated from my original Wordpress blog</em></p>
</div>

        </div>
        

<footer>
  <p class="meta">
    <span class="byline author vcard">Posted by <span class="fn">Jeremy Johnson</span></span>
    
    <time>Jul 1, 2017</time>
    
      <span class="categories">
        Tags:
        
          <a class="category" href="/tags/rvest">Rvest</a>  <a class="category" href="/tags/scraping">scraping</a>  <a class="category" href="/tags/us-news-rankings">US News rankings</a>  
    
    </span>
  </p>

  
  

  

  <p class="meta">
    

    
      <a class="basic-alignment right" href="/blog/2018-01-29-plotting-fortune-500-hqs-in-r/" title="Plotting Fortune 500 HQ&#39;s in R">Plotting Fortune 500 HQ&#39;s in R</a>
    
  </p>
  
    
      <div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'anything-is-data-is-anything';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    
  
</footer>

      </article>
    </div>
    

<aside class="sidebar thirds">
  <section class="first odd">

    
      <h1>About Me</h1>
    

    <p>
      
        <p>I&rsquo;m Jeremy, and am deeply interested in data science. Especially R.
  <br><br>
  But my educational background is in <strong>Chinese</strong> and German. <strong>Think that&rsquo;s unrelated with R</strong>? <br>
  <br> Well, I see language is a door to another world, and data science as a skillset to understanding it. <br><br> <strong>Anything is Data, and Data is Anything</strong>.
  </br><br>
  <em>Cool Websites</em> <br>
  <a href="https://www.r-bloggers.com">https://www.r-bloggers.com</a> <br></p>

<p><strong>Me on Other Platforms:</strong>  </br></p>

      
    </p>
  </section>



  
  <ul class="sidebar-nav">
    <li class="sidebar-nav-item">
      <a target="_blank" href="https://github.com/Jjohn987/" title="https://github.com/Jjohn987/"><i class="fa fa-github fa-3x"></i></a>
      
      
      
      
         
      
      <a target="_blank" href="https://www.linkedin.com/in/jeremy-johnson-09016a112" title="https://www.linkedin.com/in/jeremy-johnson-09016a112"><i class="fa fa-linkedin fa-3x"></i></a>
      <a target="_blank" href="https://stackexchange.com/users/11094434/superball10000" title="https://stackexchange.com/users/11094434/superball10000"><i class="fa fa-stack-overflow fa-3x"></i></a>
      
      
      
      
      

    
    
    </li>
  </ul>

  

  

  
  
  
    
      <section class="even">
        <h1>Recent Posts</h1>
        <ul id="recent_posts">
          
          
            
              <li class="post">
                <a href="/blog/2018-12-03-linear-classification-models---hepatic-dataset/">Linear Classification Models - Hepatic Dataset</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-09-21-first-app---halo-5-stats/">First App - Halo 5 Stats</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-06-08-part-ii-chinese-classics-word/network-plots/">Part II: Chinese Classics&#39; Word/Network Plots</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-06-01-plotting-word-bigrams-with-3-chinese-classics/">Plotting Word Bigrams with 3 Chinese Classics</a>
              </li>
            
          
            
              <li class="post">
                <a href="/blog/2018-05-29-a-tidytext-analysis-of-3-chinese-classics/">A Tidytext Analysis of 3 Chinese Classics</a>
              </li>
            
          
        </ul>
      </section>
    
  
</aside>

  </div>
</div>

<footer role="contentinfo">
  <p>Copyright &copy; 2018 Jeremy Johnson - <a href="/license/">License</a> -
  <span class="credit">Powered by <a target="_blank" href="https://gohugo.io">Hugo</a> and <a target="_blank" href="https://github.com/parsiya/hugo-octopress/">Hugo-Octopress</a> theme.
</p>

</footer>






</body>
</html>

