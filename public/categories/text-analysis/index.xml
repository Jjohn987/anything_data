<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Text Analysis on Anything is |Data| is Anything</title>
    <link>/categories/text-analysis/</link>
    <description>Recent content in Text Analysis on Anything is |Data| is Anything</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/text-analysis/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Plotting Word Bigrams with 3 Chinese Classics</title>
      <link>/blog/2018-06-01-plotting-word-bigrams-with-3-chinese-classics/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-06-01-plotting-word-bigrams-with-3-chinese-classics/</guid>
      <description>In the last post, we saw frequencies of the most common words in the Analects, Zhuangzi, and Mozi texts. The faceted plot did an excellent job of capturing a generic “idea” of each text. However, I wondered how the results might change when plotting bigrams (2 word combinations of adjacent words) as opposed to single values.
This is where I ran into a problem with Tidytext – although it worked fine for tokenizing Chinese text into single character tokens, it did not perform as well at separating the text into bigrams.</description>
    </item>
    
    <item>
      <title>A Tidytext Analysis of 3 Chinese Classics</title>
      <link>/blog/2018-05-29-a-tidytext-analysis-of-3-chinese-classics/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-05-29-a-tidytext-analysis-of-3-chinese-classics/</guid>
      <description>For a long time I’ve admired the tidytext package and its wonderful companion book Text Mining with R. After reading it I thought, “Why not undertake a project of Chinese text analysis?” I am deeply interested in Chinese philosophy but I decided to keep the analysis narrow by selecting just three works - The Analects, Zhuangzi, and the Mozi.
Following similar pace with Tidytext, I first download my data. Here I use my package ctextclassics and specifically, the function get_books(c(.</description>
    </item>
    
    <item>
      <title>Ctextclassics, my First Package</title>
      <link>/blog/2018-05-17-ctextclassics-my-first-package/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-05-17-ctextclassics-my-first-package/</guid>
      <description>My latest update is a milestone! I have authored my first ever R package which is an API caller for ctext.org. Ctext hosts numerous pre-modern Chinese texts and my package makes them available to you. The scope is broad, but think philosophical works in Confucianism, Daoism, Legalism, military doctrines, history compilations, works in medicine, and many more.
The three main functions of ctextclassics are get_chapter(&amp;quot;book&amp;quot;, &amp;quot;chapter&amp;quot;) ,get_chapters(&amp;quot;book&amp;quot;, chapters), get_books(&amp;quot;book&amp;quot;) and the internal dataframe book_list which shows the available texts.</description>
    </item>
    
    <item>
      <title>Scraping for a Booklist of the Chinese Classics</title>
      <link>/blog/2018-05-08-scraping-for-a-booklist-of-the-chinese-classics/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-05-08-scraping-for-a-booklist-of-the-chinese-classics/</guid>
      <description>Last week I was considering a project that would be interesting and unique. I decided I would like to do a text analysis on classical Chinese texts, but wasn’t sure what kind of analysis regarding which texts. I decided to keep it small - and use five of the “core” Chinese classics - The Analects, The Mengzi, Dao De Jing, Zhuangzi, and Mozi. While there are many books in Confucianism, Daoism, and Moism, these texts are often used as the most representative examples of each “genre”.</description>
    </item>
    
  </channel>
</rss>