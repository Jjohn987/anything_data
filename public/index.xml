<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anything is |Data| is Anything</title>
    <link>/</link>
    <description>Recent content on Anything is |Data| is Anything</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 06 May 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>On Relocating to Github/Netlify</title>
      <link>/blog/2018-05-06-on-relocating-to-github/netlify/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-05-06-on-relocating-to-github/netlify/</guid>
      <description>Deep, labored breathing
Hello everyone, this is the opening post on my new blog, which I’m relocating from Wordpress to GitHub Pages and Netlify. It’s so nice I’ve given it a name - because nice things have names!
But, why was I panting? The relocation effort wasn’t easy. Why did I follow through with it? Becuase it is worth the effort. This post is evidence of my victory. Now please, let me explain.</description>
    </item>
    
    <item>
      <title>Visualizing European WW1 Defense Treaties with iGraph</title>
      <link>/blog/2018-04-01-visualizing-european-ww1-defense-treaties-with-igraph/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-04-01-visualizing-european-ww1-defense-treaties-with-igraph/</guid>
      <description>I suddenly got bit by a bug to learn about network analysis. So I recalled the Correlates of War Project having a dataset about alliances. I decided to revisit them and download the data for this new project, which you can do to.
To start small, I decided to visualize a certain topic, e.g., European Defense Treaties relating to World War I. For that purpose I filtered the dataset for treaties that occured between 1878 and 1914.</description>
    </item>
    
    <item>
      <title>Visualizing European WWI Defense Treaties with iGraph in R</title>
      <link>/blog/2018-03-14-visualizing-european-wwi-defense-treaties-with-igraph-in-r/</link>
      <pubDate>Wed, 14 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-03-14-visualizing-european-wwi-defense-treaties-with-igraph-in-r/</guid>
      <description>*Migrated from my Word Press blog
Network analysis and network visualization are two fascinating aspects of data science. Just about anything can be imagined as a network. The two basic requirements are:
 There should be a “distinct set of entities”, such as humans, organizations There should exist a known relationship between these entities (Zweig, 5).  Network analysis is useful when it can reveal much about structure, relationships, or arrangements.</description>
    </item>
    
    <item>
      <title>Top MBA Programs by US News</title>
      <link>/blog/2017-07-01-top-mba-programs-by-us-news/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-07-01-top-mba-programs-by-us-news/</guid>
      <description>Migrated from My Wordpress
Somebody once asked me for reccomendations on MBA programs based on rank and tuition. I didn’t have any information on hand, but knew how toget it. Webscraping.
Webscraping is an immensly useful tool for gathering data from webpages, when it isn’t hosted on an API or stored in a file somewhere. R’s best tool for webscraping is Rvest.
So I decided to scrape information on the US News website for university rankings, which has at least 20 pages of MBA probrams available.</description>
    </item>
    
    <item>
      <title>International Organization Growth Trend</title>
      <link>/blog/2017-01-24-international-organization-growth-trend/</link>
      <pubDate>Tue, 24 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-01-24-international-organization-growth-trend/</guid>
      <description>Migrated from my original Wordpress blog
Note: This was my first “project” in R - and I had simple goals: learning data wrangling of a not-so-tidy dataset, and performing basic visualization. I wanted to learn the tidyverse set of packages, use pipe commands, and convert data from wide to long formats for different purposes.
I chose to learn the tidyverse because it gets all sorts of wrangling done about 90% of the time, (or so its said)</description>
    </item>
    
  </channel>
</rss>