---
title: 'Part II: Chinese Classics'' Word/Network Plots'
author: Jeremy Johnson
date: '2018-06-08'
slug: part-ii-chinese-classics-word-network-plots
categories: [Network Analysis, Text Analysis]
tags: [tidygraph, ggraph, Chinese text analysis]
---

This is a continuation in my series of exploratory text analysis of 3 Chinese classic  works. In the previous post, I calculated word counts for each book, and visualized common words using bar charts. This time, I'd like to examine word use *across* the texts with network visualization. The goal is to help see "what's common" *and* "what's different" between the texts regarding word usage.

Network visualization is particularly helpful for discovering simularities and differences between objects - this is because nodes and edges can form connections and clusters (or stay isolated). Thus, through a network structure we can get an idea of commonalities and differences between the word usages in these 3 works.

Disclaimer - the setup of this post is very similar to last time. I'm essentially importing the same data. So just skip past these first 2 code blocks.

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
library(tidyverse)
library(readr)
library(stringi)
library(tidygraph)
library(ggraph)


my_classics <- read_csv("~/Desktop/anything_data/content/post/my_classics.csv") %>%
  select(-1) %>%
  mutate(book = str_to_title(book))

```

```{r message=FALSE, warning=FALSE}
simple_bigram <- function(x) {
  if(length(x) < 2) {
    return(NA)
  } else {
    output_length <- length(x) - 1
    output <- vector(length = output_length)
    for(i in 1:output_length) {
      output[i] <- paste(x[i], x[i+1], sep = " ")
    }
    output
  }
}

tokenizer <- function(text) {
  unlist(lapply(stringi::stri_split_boundaries(text), function(x) simple_bigram(x)))
}

library(tmcn)

stopwordsCN <- data.frame(word = c(tmcn::stopwordsCN(),
                                   "子曰", "曰", "於", "則","吾", "子", "不", "無", "斯","與", "為", "必",
                                   "使", "非","天下", "以為","上", "下", "人", "天", "不可", "謂", "是以",
                                   "而不", "皆", "不亦", "乎", "之", "而", "者", "本", "與", "吾", "則",
                                   "以", "其", "為", "不以", "不可", "也", "矣", "子", "由", "子曰", "曰",
                                   "非其", "於", "不能", "如", "斯", "然", "君", "亦", "言", "聞", "今",
                                   "君", "不知", "无"))

single_words <- my_classics %>%
  mutate(word = map(word, function(x) unlist(stringi::stri_split_boundaries(x)))) %>%
  unnest(word) %>%
  mutate(word = str_replace_all(word, "[「」《》『』,，、。；：？！]", "")) %>%
  filter(!is.na(word)) %>%
  anti_join(stopwordsCN) %>%
  select(word, book) %>% 
  count(book, word) %>%
  group_by(book) %>%
  mutate(frequency = n/sum(n), edge_books = book) %>%
  filter(frequency > .001) %>% ungroup() %>%
  select(word, book, n, frequency, edge_books)

```

Let's get to the point - the visualizations. I've got 2 different kinds in mind. First, let's look at single word use between each text. There's bound to be significant overlap, I think. Arranging the edges in "arcs" helps avoid any overplotting or tangling that might exist in the case of too much interconnectivity.  I'd also like to point out that these plots are a bit scrunched up by the resolution due to the blog formmating, so please ignore any odd appearing nodes.

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
knitr::opts_chunk$set(fig.width=16, fig.height=12)

as_tbl_graph(single_words, directed = FALSE) %>%
  ggraph(layout = "fr") + 
  geom_edge_arc(aes(edge_width = frequency, color = edge_books, alpha = frequency)) +
  geom_node_point(alpha = .5, size = 7, show.legend = FALSE) + 
  geom_node_text(aes(label = name), color = "white",
                 family = "HiraKakuProN-W3", check_overlap = TRUE) +
  scale_edge_colour_manual(values = c("#b20047", "#00b274", "#FFB52A")) + 
  theme(axis.text.x = element_blank()) + 
  theme(axis.text.y = element_blank()) + 
  theme(panel.background = element_rect(fill = "#cddbda"),
        plot.background = element_rect(fill = "#cddbda"),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "cm")) + 
  guides(edge_width=FALSE, edge_alpha = FALSE) + 
  labs(x = NULL, y = NULL,
       title = "\nCommon Characters\n in the Analects, Mozi, and Zhuangzi\n") +
  theme(plot.title = element_text(size = 25, vjust = -10, hjust = 0.5,
                                  family = "Palatino", face = "bold.italic",
                                  color = "#3d4040")) + 
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.key = element_rect(color = "#454444", fill = "#f5fffe"),
        legend.text = element_text(size = 12, color = "#3d4040", family = "Palatino"),
        legend.key.width = unit(4, "line"),
        legend.background = element_rect(fill = "#cddbda"))
```

Thinking about this plot, let's keep in mind it is produced by filtering for words with frequency > .001. With that in mind, words in the center are used between all texts, and the words on the outer edges are unique to the individual texts. 

This method of examining "simularity" between word usage may not be analytically useful; however, I think it shows an extent of simularity and difference regarding word use. From the looks of it, I imagine that the LDA algorithm might run into confusion when I attempt to use it for distinguishing between these texts later. 

##Let's plot the the bigrams

This plot will be a directed network and it will show connections between words in the 3 texts. Here, a bigram is essentially two connected nodes. The connections (edges) between them are colored according to the text they appear in.

Warning: the plot resolution as displayed here is too small - In order for you to see the Zhuangzi bigrams (in yellow), make it larger! **cough** (Perhaps right click and open in new window?) 

```{r message=FALSE, warning=FALSE}

knitr::opts_chunk$set(fig.width=6, fig.height=6)

bigrams <- my_classics %>%
  mutate(word = str_replace_all(word, "[「」《》『』,，、。；：？！]", "")) %>%
  mutate(word = map(word, function(x) tokenizer(x))) %>%
  unnest(word) %>%
  filter(!is.na(word)) %>%
  separate(word, into = c("word1", "word2")) %>%
  filter(!word1 %in% stopwordsCN$word, !word2 %in% stopwordsCN$word) %>%
  unite("word", c("word1", "word2"), sep = " ")

book_bigrams <- bigrams %>%
  count(book, word) %>%
  arrange(book, -n) %>%
  group_by(book) %>%
  mutate(frequency = n/sum(n))


book_bigrams %>%
  separate(word, into = c("word1", "word2")) %>%
  select(word1, word2, n, frequency, book) %>%
  filter(frequency > .0009) %>%
  as_tbl_graph(directed = FALSE) %>%
  ggraph(layout = "fr") + 
  geom_edge_density() +
  geom_edge_fan(aes(color = book, edge_width = frequency),
                alpha = .70, arrow = arrow(length = unit(1.5, "mm")),
                start_cap = circle(3, "mm"), end_cap = circle(3, "mm")) +
  geom_node_point(size = 7, color = "black", alpha = .75) +
  geom_node_text(aes(label = name), color = "grey", family = "HiraKakuProN-W3", check_overlap = TRUE) +
  scale_edge_colour_manual(values = c("#b20047", "#00b274", "#fdff00"))+
  theme(axis.text.x = element_blank()) +
  theme(axis.text.y = element_blank()) +
  theme(panel.background = element_rect(fill = "#8AE3C2"),
        plot.background = element_rect(fill = "#8AE3C2"),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.margin = margin(0, 0, 0, 0, "cm")) + 
  guides(edge_width=FALSE) +
  labs(x = NULL, y = NULL, title = "Bigrams in the Analects, Mozi, and Zhuangzi") +
  theme(plot.title = element_text(size = 25, vjust = -10, hjust = 0.5,
                                  family = "Palatino", face = "italic",
                                  color = "black")) +
  theme(legend.position = "bottom", legend.title = element_blank(),
        legend.key = element_rect(color = "black", fill = "#8AE3C2"),
        legend.text = element_text(size = 12, color = "black", family = "Palatino"),
        legend.key.width = unit(4, "line"),
        legend.background = element_rect(fill = "#8AE3C2"))

```

I'd like to comment briefly on the ```tidygraph``` package which made these plots possible. Previously, I used igraph and found it powerful and quite robust, yet not too intuitive or user-friendly. Tidygraph changes all of that and allows network data to be manipulated in a way similar to the tidyverse methodology. I love tidygraph!

I hope you enjoyed these two network plots.  Until next time!




